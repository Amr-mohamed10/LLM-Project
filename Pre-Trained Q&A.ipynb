{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51464fdb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a6411c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in c:\\users\\amr\\anaconda3\\lib\\site-packages (1.24.7)\n",
      "Requirement already satisfied: transformers in c:\\users\\amr\\anaconda3\\lib\\site-packages (4.42.3)\n",
      "Requirement already satisfied: torch in c:\\users\\amr\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: PyMuPDFb==1.24.6 in c:\\users\\amr\\anaconda3\\lib\\site-packages (from PyMuPDF) (1.24.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\amr\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\amr\\anaconda3\\lib\\site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in c:\\users\\amr\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\amr\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\amr\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\amr\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\amr\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\amr\\anaconda3\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\amr\\anaconda3\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\amr\\anaconda3\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\amr\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\amr\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\amr\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\amr\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\amr\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\amr\\anaconda3\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\amr\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\amr\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\amr\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\amr\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\amr\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amr\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\amr\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amr\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\amr\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install Necessary Libraries\n",
    "# Install the required libraries for PDF extraction, transformers, and PyTorch\n",
    "!pip install PyMuPDF transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50ef3039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\amr\\anaconda3\\envs\\ai-env\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\amr\\anaconda3\\envs\\ai-env\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\amr\\anaconda3\\envs\\ai-env\\lib\\site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\amr\\anaconda3\\envs\\ai-env\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\amr\\anaconda3\\envs\\ai-env\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b70fc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environmental Factors and Pollution in Egypt:  \n",
      "Egypt, a land of towering pyramids and ancient wonders, boasts a unique environment \n",
      "shaped by a complex interplay of living (biotic) and nonliving (abiotic) factors. \n",
      "Understanding these factors is crucial for appreciating the delicate ecological balance of \n",
      "Egypt and the challenges it faces. \n",
      "A Land of Contrasts: Biotic Abundance and Aridity \n",
      "Despite the harsh desert climate, Egypt supports a diverse range of plant and animal \n",
      "life. Acacia trees with their water-conserving adaptations thrive in the desert sands, \n",
      "while along the life-giving Nile River, papyrus reeds and date palms flourish, providing \n",
      "food and shelter for a variety of animals. These vibrant ecosystems demonstrate the \n",
      "remarkable resilience of life in Egypt. \n",
      "The Nile River: A Lifeline for Egypt \n",
      "The Nile River is the heart of Egypt's ecosystem, a vital artery that has sustained human \n",
      "populations and agriculture for millennia. Its annual floods once deposited fertile silt, \n",
      "creating the Nile Delta, a crucial agricultural region. This fertile ribbon of land amidst the \n",
      "vast desert underscores the Nile's importance for life in Egypt. However, the \n",
      "construction of dams has altered the natural flood cycle, impacting the replenishment of \n",
      "fertile soils and reducing the flow of nutrients into the Mediterranean Sea, which in turn \n",
      "affects marine life. \n",
      "A Tapestry of Biodiversity and Conservation Efforts \n",
      "Nature's Bounty: A Rich tapestry of Life \n",
      "Despite the arid climate, Egypt is home to a surprising diversity of plant and animal life. \n",
      "The Red Sea, bordering eastern Egypt, boasts vibrant coral reefs teeming with marine \n",
      "life. These reefs are vital ecosystems, providing food and shelter for diverse marine \n",
      "species and protecting coastlines from erosion. Their loss would have a devastating \n",
      "impact on marine biodiversity and local economies dependent on tourism and fishing. \n",
      "Protecting Nature's Treasures: Conservation Initiatives \n",
      "Recognizing the importance o\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Extract Text from the PDF\n",
    "import fitz  # PyMuPDF is imported as fitz\n",
    "\n",
    "# Path to the PDF file\n",
    "pdf_path = 'Environmental Factors.pdf'\n",
    "\n",
    "# Open the PDF file using PyMuPDF\n",
    "pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "# Initialize an empty string to store the extracted text\n",
    "pdf_text = \"\"\n",
    "# Loop through each page in the PDF document\n",
    "for page_num in range(pdf_document.page_count):\n",
    "    page = pdf_document.load_page(page_num)  # Load the current page\n",
    "    pdf_text += page.get_text()  # Append the text of the current page to pdf_text\n",
    "\n",
    "# Print the first 2000 characters of the extracted text for verification\n",
    "print(pdf_text[:2000])  # Printing only the first 2000 characters for brevity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b45e2361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load and Prepare the Pre-trained QA Model\n",
    "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering\n",
    "import torch\n",
    "\n",
    "# Check if GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the Model class to encapsulate the QA model and its functionality\n",
    "class Model:\n",
    "    def __init__(self, model_name='distilbert-base-uncased-distilled-squad'):\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained(model_name)  # Load the tokenizer\n",
    "        self.model = DistilBertForQuestionAnswering.from_pretrained(model_name).to(device)  # Load the model and move it to the device\n",
    "\n",
    "    def get_best_answer(self, question, context, max_len=512):\n",
    "        # Encode the question and context as inputs for the model\n",
    "        inputs = self.tokenizer.encode_plus(question, context, add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
    "        input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "\n",
    "        if len(input_ids) > max_len:\n",
    "            print(f\"Input sequence is too long: {len(input_ids)} tokens. Splitting context into smaller chunks.\")\n",
    "            # Split the context into overlapping chunks if it exceeds max length\n",
    "            chunk_size = max_len - len(self.tokenizer.encode(question, add_special_tokens=False)) - 3\n",
    "            overlap = 50  # Define overlap between chunks\n",
    "            chunks = [context[i:i+chunk_size] for i in range(0, len(context), chunk_size - overlap)]\n",
    "            \n",
    "            best_answer = \"\"\n",
    "            highest_score = float('-inf')\n",
    "            \n",
    "            for chunk in chunks:\n",
    "                # Encode each chunk along with the question\n",
    "                inputs = self.tokenizer.encode_plus(question, chunk, add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
    "                input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "                \n",
    "                # Get model outputs for the current chunk\n",
    "                outputs = self.model(**inputs)\n",
    "                answer_start_scores = outputs.start_logits\n",
    "                answer_end_scores = outputs.end_logits\n",
    "\n",
    "                # Get the most likely beginning and end of the answer\n",
    "                answer_start = torch.argmax(answer_start_scores)\n",
    "                answer_end = torch.argmax(answer_end_scores) + 1\n",
    "\n",
    "                # Calculate the confidence score\n",
    "                confidence_score = torch.max(answer_start_scores) + torch.max(answer_end_scores)\n",
    "\n",
    "                # Convert tokens to string to get the answer text\n",
    "                answer = self.tokenizer.convert_tokens_to_string(self.tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "\n",
    "                # Update the best answer based on the highest confidence score\n",
    "                if confidence_score > highest_score:\n",
    "                    highest_score = confidence_score\n",
    "                    best_answer = answer\n",
    "            \n",
    "            return best_answer\n",
    "        else:\n",
    "            # If the input length is within the limit, get model outputs directly\n",
    "            outputs = self.model(**inputs)\n",
    "            answer_start_scores = outputs.start_logits\n",
    "            answer_end_scores = outputs.end_logits\n",
    "\n",
    "            # Get the most likely beginning and end of the answer\n",
    "            answer_start = torch.argmax(answer_start_scores)\n",
    "            answer_end = torch.argmax(answer_end_scores) + 1\n",
    "\n",
    "            # Convert tokens to string to get the answer text\n",
    "            answer = self.tokenizer.convert_tokens_to_string(self.tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "            return answer\n",
    "\n",
    "    def predict(self, context, question):\n",
    "        # Method to get the best answer for a given question and context\n",
    "        return {\"answer\": self.get_best_answer(question, context)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a1de15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your question (or type 'exit' to quit): What is the length of the Nile?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1280 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence is too long: 1280 tokens. Splitting context into smaller chunks.\n",
      "Question: What is the length of the Nile?\n",
      "Answer: 6 , 650 kilometers\n",
      "\n",
      "Please enter your question (or type 'exit' to quit): where is it located\n",
      "Input sequence is too long: 1276 tokens. Splitting context into smaller chunks.\n",
      "Question: where is it located\n",
      "Answer: the red sea\n",
      "\n",
      "Please enter your question (or type 'exit' to quit): exit\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Create an instance of the Model class\n",
    "model = Model()\n",
    "\n",
    "# Step 5: Interactively ask questions and get answers\n",
    "while True:\n",
    "    question = input(\"Please enter your question (or type 'exit' to quit): \")\n",
    "    if question.lower() == 'exit':\n",
    "        break\n",
    "    answer = model.predict(pdf_text, question)  # Get the answer for the input question\n",
    "    print(\"Question: \" + question)\n",
    "    print(\"Answer: \" + answer[\"answer\"] + \"\\n\")  # Print the question and answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81eec2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the length of the Nile?\n",
      "True Answer: 6,650 kilometers\n",
      "Predicted Answer: 6 , 650 kilometers\n",
      "\n",
      "Question: What is the discharge of the Nile?\n",
      "True Answer: 2,830 cubic meters per second\n",
      "Predicted Answer: 2 , 830 cubic meters per second\n",
      "\n",
      "Question: Where does the Nile originate?\n",
      "True Answer: Lake Victoria\n",
      "Predicted Answer: lake victoria in uganda\n",
      "\n",
      "Question: What are the major tributaries of the Nile?\n",
      "True Answer: White Nile and Blue Nile\n",
      "Predicted Answer: white nile and the blue nile\n",
      "\n",
      "Question: What countries does the Nile flow through?\n",
      "True Answer: Uganda, Sudan, and Egypt\n",
      "Predicted Answer: uganda , sudan , and egypt\n",
      "\n",
      "Question: What is the length of the Amazon River?\n",
      "True Answer: 7,000 kilometers\n",
      "Predicted Answer: 7 , 000 kilometers\n",
      "\n",
      "Question: What is the volume of water discharged by the Amazon River?\n",
      "True Answer: 209,000 cubic meters per second\n",
      "Predicted Answer: 209 , 000 cubic meters\n",
      "\n",
      "Question: What is the longest river in the United States?\n",
      "True Answer: Missouri River\n",
      "Predicted Answer: missouri river\n",
      "\n",
      "Question: What is the length of the Mississippi River?\n",
      "True Answer: 3,730 kilometers\n",
      "Predicted Answer: 3 , 730 kilometers\n",
      "\n",
      "Question: Where does the Mississippi River end?\n",
      "True Answer: Gulf of Mexico\n",
      "Predicted Answer: gulf of mexico\n",
      "\n",
      "Accuracy: 0.6\n",
      "Precision: 0.6\n",
      "Recall: 0.6\n",
      "F1 Score: 0.6\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Step 6: Prepare the validation dataset\n",
    "validation_data = [\n",
    "    {\"question\": \"What is the length of the Nile?\", \"context\": \"The Nile is the longest river in the world, stretching for 6,650 kilometers.\", \"answer\": \"6,650 kilometers\"},\n",
    "    {\"question\": \"What is the discharge of the Nile?\", \"context\": \"The Nile has an average discharge rate of 2,830 cubic meters per second.\", \"answer\": \"2,830 cubic meters per second\"},\n",
    "    {\"question\": \"Where does the Nile originate?\", \"context\": \"The Nile originates from Lake Victoria in Uganda.\", \"answer\": \"Lake Victoria\"},\n",
    "    {\"question\": \"What are the major tributaries of the Nile?\", \"context\": \"The two major tributaries of the Nile are the White Nile and the Blue Nile.\", \"answer\": \"White Nile and Blue Nile\"},\n",
    "    {\"question\": \"What countries does the Nile flow through?\", \"context\": \"The Nile flows through multiple countries, including Uganda, Sudan, and Egypt.\", \"answer\": \"Uganda, Sudan, and Egypt\"},\n",
    "    {\"question\": \"What is the length of the Amazon River?\", \"context\": \"The Amazon River is approximately 7,000 kilometers long.\", \"answer\": \"7,000 kilometers\"},\n",
    "    {\"question\": \"What is the volume of water discharged by the Amazon River?\", \"context\": \"The Amazon River discharges around 209,000 cubic meters of water per second.\", \"answer\": \"209,000 cubic meters per second\"},\n",
    "    {\"question\": \"What is the longest river in the United States?\", \"context\": \"The Missouri River is the longest river in the United States.\", \"answer\": \"Missouri River\"},\n",
    "    {\"question\": \"What is the length of the Mississippi River?\", \"context\": \"The Mississippi River is approximately 3,730 kilometers long.\", \"answer\": \"3,730 kilometers\"},\n",
    "    {\"question\": \"Where does the Mississippi River end?\", \"context\": \"The Mississippi River ends in the Gulf of Mexico.\", \"answer\": \"Gulf of Mexico\"}\n",
    "]\n",
    "# Step 7: Predict answers for the validation dataset\n",
    "true_answers = []\n",
    "predicted_answers = []\n",
    "\n",
    "for data in validation_data:\n",
    "    question = data['question']\n",
    "    context = data['context']\n",
    "    true_answer = data['answer']\n",
    "    predicted_answer = model.predict(context, question)[\"answer\"]\n",
    "    \n",
    "    true_answers.append(true_answer)\n",
    "    predicted_answers.append(predicted_answer)\n",
    "\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"True Answer: {true_answer}\")\n",
    "    print(f\"Predicted Answer: {predicted_answer}\\n\")\n",
    "\n",
    "# Step 8: Compute evaluation metrics\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Function to normalize answers\n",
    "def normalize_answer(s):\n",
    "    \"\"\"Lowercase, remove punctuation, and extra whitespace.\"\"\"\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    s = re.sub(r'(\\d)\\s*,\\s*(\\d)', r'\\1,\\2', s)  # Remove spaces around commas in numbers\n",
    "    s = re.sub(r'[^a-z0-9\\s,]', '', s)\n",
    "    return s\n",
    "\n",
    "# Normalize true and predicted answers\n",
    "true_answers_normalized = [normalize_answer(answer) for answer in true_answers]\n",
    "predicted_answers_normalized = [normalize_answer(answer) for answer in predicted_answers]\n",
    "\n",
    "# Calculate accuracy (exact match after normalization)\n",
    "accuracy = accuracy_score(true_answers_normalized, predicted_answers_normalized)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(true_answers_normalized, predicted_answers_normalized, average='micro', zero_division=0)\n",
    "recall = recall_score(true_answers_normalized, predicted_answers_normalized, average='micro', zero_division=0)\n",
    "f1 = f1_score(true_answers_normalized, predicted_answers_normalized, average='micro', zero_division=0)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c60cb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431c4c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106f7e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba353e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dd27d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a143943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d11f456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac0e9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai-env)",
   "language": "python",
   "name": "ai-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
